<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Hong B. Nguyen</title>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@400;700&family=Nunito+Sans:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="styles.css">
</head>
<body>

  <!-- Header -->
  <header class="main-header">
    <nav>
      <a href="index.html">Home</a>
      <a href="publications.html">Publications</a>
      <a href="Hong%20B.%20Nguyen_CV.pdf" target="_blank">CV</a>
    </nav>
  </header>

  <!-- Layout -->
  <div class="main-layout">
    <!-- Sidebar -->
    <aside class="sidebar">
      <div class="profile-card">
        <img src="img/profile/HN1.png" alt="Profile Picture of Hong B. Nguyen" class="profile-pic">
        <h3>Hong B. Nguyen</h3>
        <p>PhD Candidate, Psychology</p>
        <p>hong.nguyen [at] newschool.edu</p>
        <div class="links">
          <h4>More Sites</h4>
          <a href="https://scholar.google.com/citations?user=t_Ep51oAAAAJ&hl=en" target="_blank">Google Scholar</a>
          <a href="https://www.linkedin.com/in/hong-b-nguyen/" target="_blank">LinkedIn</a>
        </div>


      </div>
    </aside>
  
    <!-- Main Content -->
    <div class="main-content">
      <section id="about" class="card">
        <h2>About</h2>
        <p>Hi, I'm Hong B. Nguyen, a vision scientist who studies how surprisingly sophisticated implicit knowledge is quietly woven into how we perceive patterns of light landing on our retinas.</p>
        
        <p>In my research, I have discovered that the visual system makes unconscious assumptions about the seemingly invisible physical forces (such as gravity and friction) acting on objects, in order to predict whether they will change speed, and where they will move. I have also found evidence that the visual system automatically picks up on subtle visual cues to others’ intentions (e.g. that a shape is ‘chasing’ another shape, or that a facial expression signals ‘mischievous’ intent). A third branch of my research investigates how the mechanics of visual attention and information acquisition interact with higher-level cognitive processes in more complex tasks, such as navigating a webpage, or inspecting an artwork in order to have an aesthetic experience.</p>
        
        <p>Overall, my work supports two important conclusions — that fast, automatic visual processing is “smarter” than we typically give it credit for, and that seemingly simple acts of looking and seeing provide a rich foundation for higher-level thought.</p>
      </section>

      <section id="news" class="card">
        <h2>News</h2>
        <ul>
          <li>- I am honored to have received The New School's Outstanding Graduate Student Teaching Award in recognition for my teaching of courses such as <em>Fundamentals of Visual Perception</em>, <em>Developmental Psychology</em>, and <em>Cultural Psychology</em>. <span class="date">(July 2025)</span></li>

          <li>- <em>Art & Perception</em> has published the abstracts from the Visual Science of Art Conference (Cyprus, 2023).  It has been great fun serving on VSAC's small-but-mighty organizing committee for the past few years. <span class="date">(June 2024)</span></li>

          <li>- I traveled to Orlando, Florida for IEEE VR, to showcase my machine-learning system which guides users' attention within a digital interface or immersive environment in order to produce similar outcomes to past users. <span class="date">(Jan 2024)</span></li>

          <li>- Thanks to The New School for Social Research for granting me a Student Research Award, which I will use to run a series of experiments to study intuitive physics in visual cognition. <span class="date">(Dec 2023)</span></li>

          <li>- <em>Cognition</em> has published my article demonstrating a "frictive assumption" in the spatial orienting of visual attention. <span class="date">(Nov 2023)</span></li>

          <li>- My latest paper is now out in <em>JEP:HPP</em>. In it, I show that observers are more visually sensitive to gravity-opposing speed changes. <span class="date">(Jan 2023)</span></li>

          <li>- Pleased to have presented for the first time at the European Conference on Visual Perception.  I gave a talk about a new kind of attentional cueing effect, and presented a demo at Illusion Night. <span class="date">(Aug 2022)</span></li>

          <li>- Thanks to the Object Perception & Memory conference for awarding me this year's Best Talk Award.  My talk was titled, "May the Force be against you: Better sensitivity to acceleration that appears to resist gravity." <span class="date">(Nov 2021)</span></li>

          <li>- Thanks to The New School for providing an MA project grant to me, Mariah Woodruff and Leo Sedlmayer to start a <a href="https://www.nssrperception.com/gestalt-speaker-series.html" target="_blank"><em>Gestalt Speaker Series</em></a> — featuring talks by Ian Verstegen, Gary Hatfield, Liliana Albertazzi, Eline Van Geert, Ruth Kimchi, and Vebjørn Ekroll. <span class="date">(Dec 2020)</span></li>
        </ul>
      </section>

    </div>
  </div>
  
  <!-- Footer -->
  <footer>
    <p>&copy; 2024 Hong B. Nguyen. All rights reserved.</p>
  </footer>

</body>
</html>
